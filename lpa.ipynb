{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import sparse\n",
    "import networkx as nx\n",
    "from scipy.sparse import diags\n",
    "import torch.functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from networkx.readwrite import json_graph, read_gpickle\n",
    "from networkx.linalg.laplacianmatrix import laplacian_matrix\n",
    "from scipy.io import mmwrite, mmread\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn\n",
    "from scipy.io import mmread, mmwrite # spare save/load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1, 0, 3])\n",
    "def onehot(a): \n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size),a] = 1\n",
    "    return b\n",
    "# onehot(a)\n",
    "\n",
    "def load_matrix(graph):\n",
    "    adj_matrix = nx.adj_matrix(graph)\n",
    "    degree_vec = adj_matrix.sum(axis=1).astype(np.float)\n",
    "    with np.errstate(divide='ignore'):\n",
    "        d_inv_sqrt = np.squeeze(np.asarray(np.power(degree_vec, -1)))\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt) | np.isnan(d_inv_sqrt)] = 0\n",
    "    degree_matrix = diags(d_inv_sqrt, 0)\n",
    "    return adj_matrix, degree_matrix\n",
    "\n",
    "def lpa(adj_matrix,degree_matrix, labels,train_mask,iteration=10):\n",
    "    influence=labels.copy()\n",
    "    influence[np.arange(train_mask.size,labels.shape[0])]=0  # remove invisible_nodes\n",
    "    for _ in range(iteration):\n",
    "        influence = degree_matrix@adj_matrix@influence\n",
    "        influence[train_mask]=labels[train_mask]\n",
    "    pred=influence.argmax(1)\n",
    "    labels=labels.argmax(1)\n",
    "    border_nodes = (pred!=labels).nonzero()[0]\n",
    "    acc = (pred==labels).sum()/labels.size\n",
    "    return influence, acc, border_nodes\n",
    "\n",
    "# influence, acc =lpa(adj_matrix,degree_matrix,onehot_labels,train_mask,iteration=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/data0/yushi/dgl_env/lib/python3.7/site-packages/dgl/data/citation_graph.py:140: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 3327\n",
      "  NumEdges: 9228\n",
      "  NumFeats: 3703\n",
      "  NumClasses: 6\n",
      "  NumTrainingSamples: 120\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 19717\n",
      "  NumEdges: 88651\n",
      "  NumFeats: 500\n",
      "  NumClasses: 3\n",
      "  NumTrainingSamples: 60\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "cora = citegrh.load_cora()\n",
    "citeseer = citegrh.load_citeseer()\n",
    "pubmed = citegrh.load_pubmed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pubmed\n",
    "graph=data.graph\n",
    "labels=data.labels\n",
    "onehot_labels=onehot(data.labels)\n",
    "train_mask=data.train_mask.astype(np.int).nonzero()[0]\n",
    "train_labels = labels[train_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix, degree_matrix=load_matrix(graph)\n",
    "influence, acc, border_nodes =lpa(adj_matrix,degree_matrix,onehot_labels,train_mask,iteration=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarsen Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='pubmed'\n",
    "levels = 6\n",
    "reduce_results = f\"graphzoom/reduction_results/{dataset}/no_fusion/\"\n",
    "from graphzoom.utils import construct_proj_laplacian\n",
    "def check_agg(nodes, projection):\n",
    "    coarsen_nodes=[]\n",
    "    for node in nodes:\n",
    "        seed=projection[:,node].nonzero()[0][0]\n",
    "        agg_nodes = projection[seed].nonzero()[1]\n",
    "        if agg_nodes.size>1:\n",
    "            coarsen_nodes.append(node)\n",
    "    return coarsen_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"graphzoom/dataset/{}/{}.mtx\".format(dataset, dataset)\n",
    "laplacian = mmread(input_path)\n",
    "projections, coarse_adj = construct_proj_laplacian(laplacian, levels, reduce_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<7523x19717 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 19717 stored elements in Compressed Sparse Row format>,\n",
       " <3329x7523 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 7523 stored elements in Compressed Sparse Row format>,\n",
       " <1507x3329 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 3329 stored elements in Compressed Sparse Row format>,\n",
       " <695x1507 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 1507 stored elements in Compressed Sparse Row format>,\n",
       " <321x695 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 695 stored elements in Compressed Sparse Row format>,\n",
       " <161x321 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 321 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4710 5853\n"
     ]
    }
   ],
   "source": [
    "coarse_nodes = check_agg(border_nodes,projections[0])\n",
    "print(len(coarse_nodes), len(border_nodes))\n",
    "from random import shuffle\n",
    "shuffle(coarse_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_border_nodes_to_proj_matrix(projection, nodes):\n",
    "    # convert to csc\n",
    "    projs=[]\n",
    "    if type(projection) is not list:\n",
    "        projection=[projection]\n",
    "    # change first projection\n",
    "    proj=projection[0].tocsc()\n",
    "    print(proj.shape)\n",
    "    next_level_size=proj.shape[0]\n",
    "    for node in nodes:\n",
    "        proj.indices[node]=next_level_size\n",
    "        next_level_size+=1\n",
    "    projs.append(sparse.csc_matrix((proj.data, proj.indices,proj.indptr), dtype=np.longlong))\n",
    "    # change via coo_matrix\n",
    "    for i in range(1, len(projection)):\n",
    "        proj = projection[i].tocoo()\n",
    "        data = np.ones(proj.shape[1]+len(nodes)).astype(np.longlong)\n",
    "        col = np.hstack((proj.col, np.arange(proj.shape[1],proj.shape[1]+len(nodes))))\n",
    "        row = np.hstack((proj.row, np.arange(proj.shape[0],proj.shape[0]+len(nodes))))\n",
    "        projs.append(sparse.coo_matrix((data, (row, col))))\n",
    "    \n",
    "    return projs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7523, 19717)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<8523x19717 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 19717 stored elements in Compressed Sparse Column format>,\n",
       " <4329x8523 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 8523 stored elements in COOrdinate format>,\n",
       " <2507x4329 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 4329 stored elements in COOrdinate format>,\n",
       " <1695x2507 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 2507 stored elements in COOrdinate format>,\n",
       " <1321x1695 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 1695 stored elements in COOrdinate format>,\n",
       " <1161x1321 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 1321 stored elements in COOrdinate format>]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_nodes_left=1000\n",
    "border_proj=add_border_nodes_to_proj_matrix(projections[:], coarse_nodes[:coarse_nodes_left])\n",
    "border_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite(path):\n",
    "    with open(path, 'r+') as f:\n",
    "        content = f.readlines()[2:]\n",
    "        f.seek(0)\n",
    "        f.writelines(content)\n",
    "        f.truncate()\n",
    "from graphzoom.utils import mtx2matrix\n",
    "prefix=Path(f\"graphzoom/reduction_results/{dataset}/border/\")\n",
    "if not prefix.exists():\n",
    "    prefix.mkdir(parents=True)\n",
    "for i in range(len(border_proj)):\n",
    "    mmwrite(str(prefix.joinpath(f'Projection_{i+1}.mtx')), border_proj[i])\n",
    "    overwrite(str(prefix.joinpath(f'Projection_{i+1}.mtx')))\n",
    "# with open(str(prefix.joinpath(f'NumLevels.txt')), 'w') as f:\n",
    "#     f.write(str(len(border_proj)))\n",
    "\n",
    "reduce_results = f\"graphzoom/reduction_results/{dataset}/border/\"\n",
    "border_projs, border_coarse_adj = construct_proj_laplacian(laplacian, 6, reduce_results)\n",
    "mmwrite(str(prefix.joinpath(f'Gs.mtx')), border_coarse_adj[5],symmetry='symmetric')\n",
    "overwrite(str(prefix.joinpath(f'Gs.mtx')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<19717x19717 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 108365 stored elements in COOrdinate format>,\n",
       " <8523x8523 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 65587 stored elements in Compressed Sparse Row format>,\n",
       " <4329x4329 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 43069 stored elements in Compressed Sparse Row format>,\n",
       " <2507x2507 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 27871 stored elements in Compressed Sparse Row format>,\n",
       " <1695x1695 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 18137 stored elements in Compressed Sparse Row format>,\n",
       " <1321x1321 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 11953 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_coarse_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(border_projs[0]!=projections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = mtx2matrix(str(prefix.joinpath(f'Gs.mtx')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg=nx.Graph()\n",
    "# tg.add_nodes_from([1,2,3])\n",
    "tg.add_edge(1,2)\n",
    "tg.add_edge(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
