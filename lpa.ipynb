{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import sparse\n",
    "import networkx as nx\n",
    "from scipy.sparse import diags\n",
    "import torch.functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from networkx.readwrite import json_graph, read_gpickle\n",
    "from networkx.linalg.laplacianmatrix import laplacian_matrix\n",
    "from scipy.io import mmwrite, mmread\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1, 0, 3])\n",
    "def onehot(a): \n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size),a] = 1\n",
    "    return b\n",
    "# onehot(a)\n",
    "\n",
    "def load_matrix(graph):\n",
    "    adj_matrix = nx.adj_matrix(graph)\n",
    "    degree_vec = adj_matrix.sum(axis=1).astype(np.float)\n",
    "    with np.errstate(divide='ignore'):\n",
    "        d_inv_sqrt = np.squeeze(np.asarray(np.power(degree_vec, -1)))\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt) | np.isnan(d_inv_sqrt)] = 0\n",
    "    degree_matrix = diags(d_inv_sqrt, 0)\n",
    "    return adj_matrix, degree_matrix\n",
    "\n",
    "def lpa(adj_matrix,degree_matrix, labels,train_mask,iteration=10):\n",
    "    influence=labels.copy()\n",
    "    influence[np.arange(train_mask.size,labels.shape[0])]=0  # remove invisible_nodes\n",
    "    for _ in range(iteration):\n",
    "        influence = degree_matrix@adj_matrix@influence\n",
    "        influence[train_mask]=labels[train_mask]\n",
    "    pred=influence.argmax(1)\n",
    "    labels=labels.argmax(1)\n",
    "    border_nodes = (pred!=labels).nonzero()[0]\n",
    "    acc = (pred==labels).sum()/labels.size\n",
    "    return influence, acc, border_nodes\n",
    "\n",
    "# influence, acc =lpa(adj_matrix,degree_matrix,onehot_labels,train_mask,iteration=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /data/data0/yushi/.dgl//citeseer.zip from https://data.dgl.ai/dataset/citeseer.zip...\n",
      "Extracting file to /data/data0/yushi/.dgl//citeseer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/data0/yushi/dgl_env/lib/python3.7/site-packages/dgl/data/citation_graph.py:140: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 3327\n",
      "  NumEdges: 9228\n",
      "  NumFeats: 3703\n",
      "  NumClasses: 6\n",
      "  NumTrainingSamples: 120\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Downloading /data/data0/yushi/.dgl//pubmed.zip from https://data.dgl.ai/dataset/pubmed.zip...\n",
      "Extracting file to /data/data0/yushi/.dgl//pubmed\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 19717\n",
      "  NumEdges: 88651\n",
      "  NumFeats: 500\n",
      "  NumClasses: 3\n",
      "  NumTrainingSamples: 60\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "cora = citegrh.load_cora()\n",
    "citeseer = citegrh.load_citeseer()\n",
    "pubmed = citegrh.load_pubmed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pubmed\n",
    "graph=data.graph\n",
    "labels=data.labels\n",
    "onehot_labels=onehot(data.labels)\n",
    "train_mask=data.train_mask.astype(np.int).nonzero()[0]\n",
    "train_labels = labels[train_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix, degree_matrix=load_matrix(graph)\n",
    "influence, acc, border_nodes =lpa(adj_matrix,degree_matrix,onehot_labels,train_mask,iteration=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarsen Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='pubmed'\n",
    "levels = 2\n",
    "reduce_results = f\"graphzoom/reduction_results/{dataset}/fusion/\"\n",
    "from graphzoom.utils import construct_proj_laplacian\n",
    "def check_agg(nodes, projection):\n",
    "    agg_sum=0\n",
    "    for node in nodes:\n",
    "        seed=projection[:,node].nonzero()[0][0]\n",
    "        agg_nodes = projection[seed].nonzero()[1]\n",
    "        if agg_nodes.size>1:\n",
    "            agg_sum+=1\n",
    "    return agg_sum, len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections, coarse_adj = construct_proj_laplacian(adj_matrix, levels, reduce_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5152, 5853)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_agg(border_nodes,projections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
