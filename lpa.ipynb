{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import sparse\n",
    "import networkx as nx\n",
    "from scipy.sparse import diags\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from networkx.readwrite import json_graph, read_gpickle\n",
    "from networkx.linalg.laplacianmatrix import laplacian_matrix\n",
    "from scipy.io import mmwrite, mmread\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn\n",
    "from scipy.io import mmread, mmwrite # spare save/load\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import trange, tqdm\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1, 0, 3])\n",
    "from scipy import sparse\n",
    "def onehot(a): \n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size),a] = 1\n",
    "    return b\n",
    "# onehot(a)\n",
    "\n",
    "def load_matrix(graph):\n",
    "    if 'networkx' in str(type(graph)):\n",
    "        adj_matrix = nx.adj_matrix(graph)\n",
    "    else:\n",
    "        adj_matrix=graph\n",
    "    degree_vec = adj_matrix.sum(axis=1).astype(np.float)\n",
    "    with np.errstate(divide='ignore'):\n",
    "        d_inv_sqrt = np.squeeze(np.asarray(np.power(degree_vec, -1)))\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt) | np.isnan(d_inv_sqrt)] = 0\n",
    "    degree_matrix = diags(d_inv_sqrt, 0)\n",
    "    return adj_matrix, degree_matrix\n",
    "\n",
    "def lpa(adj_matrix,degree_matrix, labels,train_mask,test_mask, iteration=10):\n",
    "    influence=labels.copy()\n",
    "    influence[np.arange(train_mask.size,labels.shape[0])]=0  # remove invisible_nodes\n",
    "    for _ in range(iteration):\n",
    "        influence = degree_matrix@adj_matrix@influence\n",
    "        influence[train_mask]=labels[train_mask]\n",
    "    pred=influence.argmax(1)\n",
    "    labels=labels.argmax(1)\n",
    "    border_nodes = (pred!=labels).nonzero()[0]\n",
    "    acc = (pred[test_mask]==labels[test_mask]).sum()/labels[test_mask].size\n",
    "    return influence, acc, border_nodes, influence\n",
    "\n",
    "# influence, acc =lpa(adj_matrix,degree_matrix,onehot_labels,train_mask,iteration=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/data0/yushi/dgl_env/lib/python3.7/site-packages/dgl/data/citation_graph.py:140: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 3327\n",
      "  NumEdges: 9228\n",
      "  NumFeats: 3703\n",
      "  NumClasses: 6\n",
      "  NumTrainingSamples: 120\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 19717\n",
      "  NumEdges: 88651\n",
      "  NumFeats: 500\n",
      "  NumClasses: 3\n",
      "  NumTrainingSamples: 60\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Finished data loading.\n",
      "  NumNodes: 232965\n",
      "  NumEdges: 114615892\n",
      "  NumFeats: 602\n",
      "  NumClasses: 41\n",
      "  NumTrainingSamples: 153431\n",
      "  NumValidationSamples: 23831\n",
      "  NumTestSamples: 55703\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "cora = citegrh.load_cora()\n",
    "citeseer = citegrh.load_citeseer()\n",
    "pubmed = citegrh.load_pubmed()\n",
    "reddit = dgl.data.RedditDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=reddit\n",
    "dataset='reddit'\n",
    "graph=data.graph\n",
    "labels=data.labels\n",
    "onehot_labels=onehot(data.labels)\n",
    "train_mask=data.train_mask.astype(np.int).nonzero()[0]\n",
    "test_mask=data.test_mask.astype(np.int).nonzero()[0]\n",
    "train_labels = labels[train_mask]\n",
    "onehot_labels = F.one_hot(torch.LongTensor(labels)).numpy()\n",
    "levels = 4\n",
    "reduce_results = f\"graphzoom/reduction_results/{dataset}/no_fusion/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reddit\n",
    "\n",
    "dataset_prefix='/data/data0/yushi/'\n",
    "dataset_dir=f'{dataset_prefix}/dataset/{dataset}'\n",
    "npz_path = Path(f'{dataset_dir}/{dataset}.npz')\n",
    "graph = sparse.load_npz(str(npz_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix, degree_matrix=load_matrix(graph)\n",
    "# %timeit \n",
    "# influence, acc, border_nodes, influence =lpa(adj_matrix,degree_matrix,onehot_labels,train_mask,test_mask,iteration=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.742"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarsen Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from graphzoom.utils import construct_proj_laplacian, mtx2matrix\n",
    "def check_agg(nodes, projection):\n",
    "    coarsen_nodes=[]\n",
    "    for node in nodes:\n",
    "        seed=projection[:,node].nonzero()[0][0]\n",
    "        agg_nodes = projection[seed].nonzero()[1]\n",
    "        if agg_nodes.size>1:\n",
    "            coarsen_nodes.append(node)\n",
    "    return coarsen_nodes\n",
    "\n",
    "def onehot_proj(projection, train_mask):\n",
    "#     seed=projection[:,node].nonzero()[0][0]\n",
    "    col, row= [], []\n",
    "    for seed in trange(projection.shape[0]):\n",
    "        agg_nodes = projection[seed].nonzero()[1]\n",
    "#         print(agg_nodes)\n",
    "        train_nodes = [node for node in agg_nodes if node in train_mask]\n",
    "        unknown_nodes = [node for node in agg_nodes if node not in train_nodes]\n",
    "        if len(train_nodes): # \n",
    "            agg_group=defaultdict(list)\n",
    "            for node in train_nodes:\n",
    "                agg_group[labels[node]].append(node)\n",
    "            most_common=sorted(agg_group.items(), key=lambda x:len(x[1]), reverse=True)[0][0]\n",
    "            agg_group[most_common]+=unknown_nodes\n",
    "#             if len(agg_group)>1:\n",
    "#                 pdb.set_trace()\n",
    "            for hypter_node in agg_group:\n",
    "                row+=[row[-1]+1 if len(row) else 0]*len(agg_group[hypter_node])\n",
    "                col+=agg_group[hypter_node]\n",
    "        else: # feed unknown\n",
    "            row += [row[-1]+1 if len(row) else 0] * len(unknown_nodes)\n",
    "            col += unknown_nodes\n",
    "            \n",
    "#     pdb.set_trace()\n",
    "    assert len(col)==projection.shape[1]\n",
    "    data = np.ones(projection.shape[1])\n",
    "    proj = sparse.coo_matrix((data, (row, col)))\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<82494x232965 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 232965 stored elements in Compressed Sparse Row format>,\n",
       " <30592x82494 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 82494 stored elements in Compressed Sparse Row format>,\n",
       " <11865x30592 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 30592 stored elements in Compressed Sparse Row format>,\n",
       " <4888x11865 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 11865 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = \"graphzoom/dataset/{}/{}.mtx\".format(dataset, dataset)\n",
    "print('loading mtx')\n",
    "laplacian = mmread(input_path)\n",
    "print('loading finished')\n",
    "projections, coarse_adj = construct_proj_laplacian(laplacian, levels, reduce_results)\n",
    "projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. one_hot -> merge\n",
    "2. multi_hot -> merge in separate\n",
    "3. unknown -> most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82494/82494 [00:54<00:00, 1509.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# train_mask\n",
    "proj = [onehot_proj(projections[0], train_mask)]\n",
    "# d={1:[1,2,3],2:[1,2,3,3,3,3,]}\n",
    "# sorted(d.items(), key=lambda x:len(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<89741x232965 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 232965 stored elements in COOrdinate format>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5201 5942\n"
     ]
    }
   ],
   "source": [
    "coarse_nodes = check_agg(border_nodes,projections[0])\n",
    "print(len(coarse_nodes), len(border_nodes))\n",
    "from random import shuffle\n",
    "shuffle(coarse_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_border_nodes_to_proj_matrix(projection, nodes):\n",
    "    # convert to csc\n",
    "    projs=[]\n",
    "    if type(projection) is not list:\n",
    "        projection=[projection]\n",
    "    # change first projection\n",
    "    proj=projection[0].tocsc()\n",
    "    print(proj.shape)\n",
    "    next_level_size=proj.shape[0]\n",
    "    for node in nodes:\n",
    "        proj.indices[node]=next_level_size\n",
    "        next_level_size+=1\n",
    "    projs.append(sparse.csc_matrix((proj.data, proj.indices,proj.indptr), dtype=np.longlong))\n",
    "    # change via coo_matrix\n",
    "    for i in range(1, len(projection)):\n",
    "        proj = projection[i].tocoo()\n",
    "        data = np.ones(proj.shape[1]+len(nodes)).astype(np.longlong)\n",
    "        col = np.hstack((proj.col, np.arange(proj.shape[1],proj.shape[1]+len(nodes))))\n",
    "        row = np.hstack((proj.row, np.arange(proj.shape[0],proj.shape[0]+len(nodes))))\n",
    "        projs.append(sparse.coo_matrix((data, (row, col))))\n",
    "    \n",
    "    return projs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82494, 232965)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<83494x232965 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 232965 stored elements in Compressed Sparse Column format>,\n",
       " <31592x83494 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 83494 stored elements in COOrdinate format>,\n",
       " <12865x31592 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 31592 stored elements in COOrdinate format>,\n",
       " <5888x12865 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 12865 stored elements in COOrdinate format>]"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_nodes_left=1000\n",
    "border_proj=add_border_nodes_to_proj_matrix(projections[:], coarse_nodes[:coarse_nodes_left])\n",
    "proj = border_proj\n",
    "border_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite(path):\n",
    "    with open(path, 'r+') as f:\n",
    "        content = f.readlines()[2:]\n",
    "        f.seek(0)\n",
    "        f.writelines(content)\n",
    "        f.truncate()\n",
    "from graphzoom.utils import mtx2matrix\n",
    "prefix=Path(f\"graphzoom/reduction_results/{dataset}/one_hot/\")\n",
    "if not prefix.exists():\n",
    "    prefix.mkdir(parents=True)\n",
    "for i in range(len(proj)):\n",
    "    mmwrite(str(prefix.joinpath(f'Projection_{i+1}.mtx')), proj[i])\n",
    "    overwrite(str(prefix.joinpath(f'Projection_{i+1}.mtx')))\n",
    "# with open(str(prefix.joinpath(f'NumLevels.txt')), 'w') as f:\n",
    "#     f.write(str(len(border_proj)))\n",
    "\n",
    "reduce_results = f\"graphzoom/reduction_results/{dataset}/border/\"\n",
    "border_projs, border_coarse_adj = construct_proj_laplacian(laplacian, 4, reduce_results)\n",
    "mmwrite(str(prefix.joinpath(f'Gs.mtx')), border_coarse_adj[3],symmetry='symmetric')\n",
    "overwrite(str(prefix.joinpath(f'Gs.mtx')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<232965x232965 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 114848857 stored elements in COOrdinate format>,\n",
       " <83494x83494 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 58028143 stored elements in Compressed Sparse Row format>,\n",
       " <31592x31592 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 28021941 stored elements in Compressed Sparse Row format>,\n",
       " <12865x12865 sparse matrix of type '<class 'numpy.longlong'>'\n",
       " \twith 11493302 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "border_coarse_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(border_projs[0]!=projections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = mtx2matrix(str(prefix.joinpath(f'Gs.mtx')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg=nx.Graph()\n",
    "# tg.add_nodes_from([1,2,3])\n",
    "tg.add_edge(1,2)\n",
    "tg.add_edge(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
